{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f7921bc",
   "metadata": {},
   "source": [
    "# üìã Estructura del Proyecto - 5 Etapas\n",
    "\n",
    "Este notebook est√° organizado en 5 etapas claramente definidas para facilitar su comprensi√≥n y ejecuci√≥n:\n",
    "\n",
    "## üîß Etapa 1: Configuraci√≥n y Descarga de Datos\n",
    "- Instalaci√≥n de dependencias necesarias\n",
    "- Verificaci√≥n de GPU y configuraci√≥n del dispositivo\n",
    "- Descarga autom√°tica del dataset Stanford Dogs\n",
    "\n",
    "## üìä Etapa 2: Preprocesamiento y An√°lisis Exploratorio\n",
    "- An√°lisis de la estructura del dataset\n",
    "- Visualizaci√≥n de muestras de datos\n",
    "- Implementaci√≥n de transformaciones y data loaders\n",
    "\n",
    "## üèóÔ∏è Etapa 3: Arquitectura del Modelo\n",
    "- Definici√≥n del modelo CNN personalizado\n",
    "- Configuraci√≥n de optimizador y funci√≥n de p√©rdida\n",
    "- Preparaci√≥n para mixed precision training\n",
    "\n",
    "## üöÄ Etapa 4: Entrenamiento\n",
    "- Entrenamiento del modelo por 5 √©pocas\n",
    "- Monitoreo en tiempo real del progreso\n",
    "- Guardado del mejor modelo\n",
    "\n",
    "## üìà Etapa 5: Evaluaci√≥n y Resultados\n",
    "- Evaluaci√≥n del modelo en conjunto de prueba\n",
    "- Visualizaci√≥n de predicciones\n",
    "- An√°lisis de m√©tricas de rendimiento\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721e5407",
   "metadata": {},
   "source": [
    "# Clasificaci√≥n de Razas de Perros - Stanford Dogs Dataset\n",
    "## Framework: PyTorch con CUDA\n",
    "### 120 clases de razas caninas con data augmentation y redes profundas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f1da63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 28 11:26:22 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 572.61                 Driver Version: 572.61         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   46C    P8              8W /   85W |    2887MiB /   4096MiB |     33%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            3860    C+G   ...4__w2gh52qy24etm\\Nahimic3.exe      N/A      |\n",
      "|    0   N/A  N/A            6620    C+G   ...UI3Apps\\PowerToys.Peek.UI.exe      N/A      |\n",
      "|    0   N/A  N/A           10640    C+G   ...Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A           13012    C+G   ...lpaper_engine\\wallpaper32.exe      N/A      |\n",
      "|    0   N/A  N/A           13020    C+G   ...nature and Identification.exe      N/A      |\n",
      "|    0   N/A  N/A           13036    C+G   ...8bbwe\\Microsoft.CmdPal.UI.exe      N/A      |\n",
      "|    0   N/A  N/A           15844    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           15916    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           17376    C+G   ...Toys\\PowerToys.FancyZones.exe      N/A      |\n",
      "|    0   N/A  N/A           17404    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           17496    C+G   ...4__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A           18708    C+G   ....0.3296.93\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           18972    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           19184    C+G   ...s\\PowerToys.ColorPickerUI.exe      N/A      |\n",
      "|    0   N/A  N/A           19636    C+G   D:\\Microsoft VS Code\\Code.exe         N/A      |\n",
      "|    0   N/A  N/A           20564    C+G   ...Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A           21700    C+G   ...s\\PowerToys.PowerLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A           23644    C+G   ....0.3296.93\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           24936    C+G   ...64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A           25012    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           29368      C   ...s\\Python\\Python313\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           29512    C+G   ...novoVantage\\LenovoVantage.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.22.1+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.0.16)\n",
      "Requirement already satisfied: albumentations in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.0.8)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: torch in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from timm) (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from timm) (0.22.1+cu118)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from timm) (0.33.1)\n",
      "Requirement already satisfied: safetensors in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (1.15.3)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (2.11.7)\n",
      "Requirement already satisfied: albucore==0.0.24 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (4.11.0.86)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albucore==0.0.24->albumentations) (3.12.5)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albucore==0.0.24->albumentations) (6.4.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub->timm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub->timm) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->timm) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->timm) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->timm) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (2025.4.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.2)\n",
      "Requirement already satisfied: gdown in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gdown) (4.13.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4->gdown) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4->gdown) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (2025.4.26)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Verificar GPU disponible\n",
    "!nvidia-smi\n",
    "\n",
    "# Instalar dependencias\n",
    "!python -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!python -m pip install timm albumentations matplotlib seaborn scikit-learn\n",
    "!python -m pip install wget gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a7acb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cristhian Ismael\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "Memoria GPU disponible: 4.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "import wget\n",
    "import tarfile\n",
    "from PIL import Image\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configurar device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Usando dispositivo: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memoria GPU disponible: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b1e8e9",
   "metadata": {},
   "source": [
    "# üìä ETAPA 2: PREPROCESAMIENTO Y AN√ÅLISIS EXPLORATORIO\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf5b6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargar Stanford Dogs Dataset\n",
    "def download_stanford_dogs():\n",
    "    if not os.path.exists('stanford_dogs'):\n",
    "        print(\"Descargando Stanford Dogs Dataset...\")\n",
    "        \n",
    "        # URLs del dataset\n",
    "        images_url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\"\n",
    "        annotations_url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/annotation.tar\"\n",
    "        lists_url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar\"\n",
    "        \n",
    "        os.makedirs('stanford_dogs', exist_ok=True)\n",
    "        \n",
    "        # Descargar archivos\n",
    "        try:\n",
    "            print(\"Descargando im√°genes...\")\n",
    "            wget.download(images_url, 'stanford_dogs/images.tar')\n",
    "            print(\"\\nDescargando anotaciones...\")\n",
    "            wget.download(annotations_url, 'stanford_dogs/annotation.tar')\n",
    "            print(\"\\nDescargando listas...\")\n",
    "            wget.download(lists_url, 'stanford_dogs/lists.tar')\n",
    "            \n",
    "            # Extraer archivos\n",
    "            for tar_file in ['images.tar', 'annotation.tar', 'lists.tar']:\n",
    "                print(f\"\\nExtrayendo {tar_file}...\")\n",
    "                with tarfile.open(f'stanford_dogs/{tar_file}', 'r') as tar:\n",
    "                    tar.extractall('stanford_dogs/')\n",
    "                os.remove(f'stanford_dogs/{tar_file}')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error descargando dataset: {e}\")\n",
    "            print(\"Usando dataset alternativo...\")\n",
    "            # Usar torchvision como alternativa\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "download_stanford_dogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d543a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cristhian Ismael\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "C:\\Users\\Cristhian Ismael\\AppData\\Local\\Temp\\ipykernel_30608\\2063229364.py:64: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o dataset entrenamiento: 16464\n",
      "Tama√±o dataset validaci√≥n: 20580\n",
      "N√∫mero de clases: 120\n"
     ]
    }
   ],
   "source": [
    "# Preparar dataset con augmentaci√≥n avanzada\n",
    "class StanfordDogsDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, is_train=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.class_to_idx = {}\n",
    "        \n",
    "        self._load_dataset()\n",
    "    \n",
    "    def _load_dataset(self):\n",
    "        images_dir = os.path.join(self.root_dir, 'Images')\n",
    "        if os.path.exists(images_dir):\n",
    "            classes = sorted(os.listdir(images_dir))\n",
    "            self.class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "            \n",
    "            for class_name in classes:\n",
    "                class_dir = os.path.join(images_dir, class_name)\n",
    "                if os.path.isdir(class_dir):\n",
    "                    for img_name in os.listdir(class_dir):\n",
    "                        if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                            self.images.append(os.path.join(class_dir, img_name))\n",
    "                            self.labels.append(self.class_to_idx[class_name])\n",
    "        else:\n",
    "            # Usar datos sint√©ticos para demostraci√≥n\n",
    "            print(\"Generando datos sint√©ticos para demostraci√≥n...\")\n",
    "            self.class_to_idx = {f'breed_{i:03d}': i for i in range(120)}\n",
    "            for i in range(12000):  # 100 im√°genes por clase\n",
    "                self.images.append(f'synthetic_image_{i}.jpg')\n",
    "                self.labels.append(i % 120)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Cargar imagen o crear sint√©tica\n",
    "        if os.path.exists(img_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            # Imagen sint√©tica para demostraci√≥n\n",
    "            image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        return image.float(), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Transformaciones con albumentations para mejor rendimiento\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.RandomCrop(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=30, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "    A.Blur(blur_limit=3, p=0.3),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Crear datasets\n",
    "train_dataset = StanfordDogsDataset('stanford_dogs', transform=train_transform, is_train=True)\n",
    "val_dataset = StanfordDogsDataset('stanford_dogs', transform=val_transform, is_train=False)\n",
    "\n",
    "# Split train/val\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, _ = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "print(f'Tama√±o dataset entrenamiento: {len(train_dataset)}')\n",
    "print(f'Tama√±o dataset validaci√≥n: {len(val_dataset)}')\n",
    "print(f'N√∫mero de clases: {len(train_dataset.dataset.class_to_idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d4005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo creado con 11,548,832 par√°metros\n",
      "Par√°metros entrenables: 11,548,832\n"
     ]
    }
   ],
   "source": [
    "# Modelo optimizado con EfficientNet y t√©cnicas avanzadas\n",
    "class DogBreedClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=120, model_name='efficientnet_b3'):\n",
    "        super(DogBreedClassifier, self).__init__()\n",
    "        \n",
    "        # Backbone preentrenado\n",
    "        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0)\n",
    "        \n",
    "        # Feature dimension\n",
    "        feature_dim = self.backbone.num_features\n",
    "        \n",
    "        # Clasificador con dropout y batch normalization\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(feature_dim),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(feature_dim, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Inicializaci√≥n de pesos\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        if len(features.shape) > 2:\n",
    "            features = torch.mean(features, dim=[-2, -1])  # Global average pooling\n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "# Crear modelo optimizado\n",
    "model = DogBreedClassifier(num_classes=120, model_name='efficientnet_b3')\n",
    "model = model.to(device)\n",
    "\n",
    "# Compilar con optimizaciones CUDA\n",
    "if torch.cuda.is_available():\n",
    "    model = torch.jit.script(model)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "\n",
    "print(f'Modelo creado con {sum(p.numel() for p in model.parameters()):,} par√°metros')\n",
    "print(f'Par√°metros entrenables: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c41c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 32\n",
      "Steps por √©poca: 515\n",
      "Using mixed precision: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristhian Ismael\\AppData\\Local\\Temp\\ipykernel_30608\\3037572908.py:42: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n de entrenamiento optimizada\n",
    "batch_size = 32 if torch.cuda.is_available() else 16\n",
    "num_workers = 4\n",
    "\n",
    "# DataLoaders optimizados\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "# Optimizer con weight decay y momentum\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Scheduler con warmup\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.1,\n",
    "    div_factor=10,\n",
    "    final_div_factor=100\n",
    ")\n",
    "\n",
    "# Loss function con label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# M√©tricas\n",
    "scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "\n",
    "print(f'Batch size: {batch_size}')\n",
    "print(f'Steps por √©poca: {len(train_loader)}')\n",
    "print(f'Using mixed precision: {scaler is not None}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eeee3c",
   "metadata": {},
   "source": [
    "# üèóÔ∏è ETAPA 3: ARQUITECTURA DEL MODELO\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1dc255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento...\n",
      "\n",
      "√âpoca 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/515 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Funci√≥n de entrenamiento optimizada\n",
    "def train_epoch(model, loader, optimizer, criterion, scheduler, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        total += target.size(0)\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{100.*correct/total:.2f}%',\n",
    "            'LR': f'{scheduler.get_last_lr()[0]:.6f}'\n",
    "        })\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc='Validation')\n",
    "        for data, target in pbar:\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "            \n",
    "            if scaler is not None:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, target)\n",
    "            else:\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "# Entrenamiento\n",
    "epochs = 5\n",
    "best_acc = 0\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "print(\"Iniciando entrenamiento...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\n√âpoca {epoch+1}/{epochs}')\n",
    "    \n",
    "    # Entrenamiento\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, scheduler, scaler)\n",
    "    \n",
    "    # Validaci√≥n\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "    \n",
    "    # Guardar m√©tricas\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    # Guardar mejor modelo\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_acc': best_acc,\n",
    "        }, 'best_dog_classifier.pth')\n",
    "        print(f'Nuevo mejor modelo guardado! Accuracy: {best_acc:.2f}%')\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f'\\nEntrenamiento completado en {training_time/60:.2f} minutos')\n",
    "print(f'Mejor accuracy: {best_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b652b8a2",
   "metadata": {},
   "source": [
    "# üöÄ ETAPA 4: ENTRENAMIENTO\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6daea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de resultados\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(val_losses, label='Val Loss', color='red')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(train_accs, label='Train Acc', color='blue')\n",
    "plt.plot(val_accs, label='Val Acc', color='red')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Learning rate\n",
    "plt.subplot(1, 3, 3)\n",
    "lrs = [scheduler.get_last_lr()[0] for _ in range(len(train_losses))]\n",
    "plt.plot(lrs, color='green')\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estad√≠sticas finales\n",
    "print(f\"\\n=== RESULTADOS FINALES ===\")\n",
    "print(f\"Mejor accuracy de validaci√≥n: {best_acc:.2f}%\")\n",
    "print(f\"Tiempo total de entrenamiento: {training_time/60:.2f} minutos\")\n",
    "print(f\"Promedio por √©poca: {training_time/epochs:.2f} segundos\")\n",
    "print(f\"N√∫mero de par√°metros: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Tama√±o del modelo: {os.path.getsize('best_dog_classifier.pth')/1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b1190",
   "metadata": {},
   "source": [
    "# üìà ETAPA 5: EVALUACI√ìN Y RESULTADOS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21396fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n de inferencia optimizada\n",
    "def predict_dog_breed(model, image_path, class_names, top_k=5):\n",
    "    model.eval()\n",
    "    \n",
    "    # Cargar y preprocesar imagen\n",
    "    if os.path.exists(image_path):\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        # Imagen sint√©tica para demostraci√≥n\n",
    "        image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Aplicar transformaciones\n",
    "    transformed = val_transform(image=image)\n",
    "    input_tensor = transformed['image'].unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(input_tensor)\n",
    "        else:\n",
    "            output = model(input_tensor)\n",
    "        \n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        top_k_probs, top_k_indices = torch.topk(probabilities, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for i in range(top_k):\n",
    "        breed_idx = top_k_indices[0][i].item()\n",
    "        prob = top_k_probs[0][i].item()\n",
    "        breed_name = list(class_names.keys())[breed_idx] if breed_idx < len(class_names) else f'Breed_{breed_idx}'\n",
    "        results.append((breed_name, prob))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Ejemplo de predicci√≥n\n",
    "class_names = train_dataset.dataset.class_to_idx\n",
    "example_predictions = predict_dog_breed(model, 'example_dog.jpg', class_names)\n",
    "\n",
    "print(\"\\n=== PREDICCI√ìN DE EJEMPLO ===\")\n",
    "for i, (breed, prob) in enumerate(example_predictions, 1):\n",
    "    print(f\"{i}. {breed}: {prob*100:.2f}%\")\n",
    "\n",
    "print(\"\\n¬°Modelo de clasificaci√≥n de razas de perros completado!\")\n",
    "print(\"Caracter√≠sticas implementadas:\")\n",
    "print(\"‚úì EfficientNet-B3 como backbone\")\n",
    "print(\"‚úì Data augmentation avanzado con Albumentations\")\n",
    "print(\"‚úì Optimizaci√≥n CUDA con mixed precision\")\n",
    "print(\"‚úì Scheduler OneCycleLR con warmup\")\n",
    "print(\"‚úì Label smoothing y regularizaci√≥n\")\n",
    "print(\"‚úì 120 clases de razas caninas\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
