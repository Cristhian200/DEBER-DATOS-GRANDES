{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f7921bc",
   "metadata": {},
   "source": [
    "# 📋 Estructura del Proyecto - 5 Etapas\n",
    "\n",
    "Este notebook está organizado en 5 etapas claramente definidas para facilitar su comprensión y ejecución:\n",
    "\n",
    "## 🔧 Etapa 1: Configuración y Descarga de Datos\n",
    "- Instalación de dependencias necesarias\n",
    "- Verificación de GPU y configuración del dispositivo\n",
    "- Descarga automática del dataset Stanford Dogs\n",
    "\n",
    "## 📊 Etapa 2: Preprocesamiento y Análisis Exploratorio\n",
    "- Análisis de la estructura del dataset\n",
    "- Visualización de muestras de datos\n",
    "- Implementación de transformaciones y data loaders\n",
    "\n",
    "## 🏗️ Etapa 3: Arquitectura del Modelo\n",
    "- Definición del modelo CNN personalizado\n",
    "- Configuración de optimizador y función de pérdida\n",
    "- Preparación para mixed precision training\n",
    "\n",
    "## 🚀 Etapa 4: Entrenamiento\n",
    "- Entrenamiento del modelo por 5 épocas\n",
    "- Monitoreo en tiempo real del progreso\n",
    "- Guardado del mejor modelo\n",
    "\n",
    "## 📈 Etapa 5: Evaluación y Resultados\n",
    "- Evaluación del modelo en conjunto de prueba\n",
    "- Visualización de predicciones\n",
    "- Análisis de métricas de rendimiento\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721e5407",
   "metadata": {},
   "source": [
    "# Clasificación de Razas de Perros - Stanford Dogs Dataset\n",
    "## Framework: PyTorch con CUDA\n",
    "### 120 clases de razas caninas con data augmentation y redes profundas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f1da63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 28 11:26:22 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 572.61                 Driver Version: 572.61         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   46C    P8              8W /   85W |    2887MiB /   4096MiB |     33%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            3860    C+G   ...4__w2gh52qy24etm\\Nahimic3.exe      N/A      |\n",
      "|    0   N/A  N/A            6620    C+G   ...UI3Apps\\PowerToys.Peek.UI.exe      N/A      |\n",
      "|    0   N/A  N/A           10640    C+G   ...Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A           13012    C+G   ...lpaper_engine\\wallpaper32.exe      N/A      |\n",
      "|    0   N/A  N/A           13020    C+G   ...nature and Identification.exe      N/A      |\n",
      "|    0   N/A  N/A           13036    C+G   ...8bbwe\\Microsoft.CmdPal.UI.exe      N/A      |\n",
      "|    0   N/A  N/A           15844    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           15916    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           17376    C+G   ...Toys\\PowerToys.FancyZones.exe      N/A      |\n",
      "|    0   N/A  N/A           17404    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           17496    C+G   ...4__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A           18708    C+G   ....0.3296.93\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           18972    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           19184    C+G   ...s\\PowerToys.ColorPickerUI.exe      N/A      |\n",
      "|    0   N/A  N/A           19636    C+G   D:\\Microsoft VS Code\\Code.exe         N/A      |\n",
      "|    0   N/A  N/A           20564    C+G   ...Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A           21700    C+G   ...s\\PowerToys.PowerLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A           23644    C+G   ....0.3296.93\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           24936    C+G   ...64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A           25012    C+G   ...crosoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A           29368      C   ...s\\Python\\Python313\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           29512    C+G   ...novoVantage\\LenovoVantage.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.22.1+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.0.16)\n",
      "Requirement already satisfied: albumentations in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.0.8)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: torch in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from timm) (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from timm) (0.22.1+cu118)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from timm) (0.33.1)\n",
      "Requirement already satisfied: safetensors in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (1.15.3)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (2.11.7)\n",
      "Requirement already satisfied: albucore==0.0.24 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albumentations) (4.11.0.86)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albucore==0.0.24->albumentations) (3.12.5)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from albucore==0.0.24->albumentations) (6.4.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub->timm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub->timm) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->timm) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->timm) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->timm) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface_hub->timm) (2025.4.26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.2)\n",
      "Requirement already satisfied: gdown in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gdown) (4.13.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gdown) (3.13.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4->gdown) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4->gdown) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (2025.4.26)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\cristhian ismael\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Verificar GPU disponible\n",
    "!nvidia-smi\n",
    "\n",
    "# Instalar dependencias\n",
    "!python -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!python -m pip install timm albumentations matplotlib seaborn scikit-learn\n",
    "!python -m pip install wget gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a7acb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cristhian Ismael\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "Memoria GPU disponible: 4.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "import wget\n",
    "import tarfile\n",
    "from PIL import Image\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configurar device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Usando dispositivo: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memoria GPU disponible: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b1e8e9",
   "metadata": {},
   "source": [
    "# 📊 ETAPA 2: PREPROCESAMIENTO Y ANÁLISIS EXPLORATORIO\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf5b6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargar Stanford Dogs Dataset\n",
    "def download_stanford_dogs():\n",
    "    if not os.path.exists('stanford_dogs'):\n",
    "        print(\"Descargando Stanford Dogs Dataset...\")\n",
    "        \n",
    "        # URLs del dataset\n",
    "        images_url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\"\n",
    "        annotations_url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/annotation.tar\"\n",
    "        lists_url = \"http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar\"\n",
    "        \n",
    "        os.makedirs('stanford_dogs', exist_ok=True)\n",
    "        \n",
    "        # Descargar archivos\n",
    "        try:\n",
    "            print(\"Descargando imágenes...\")\n",
    "            wget.download(images_url, 'stanford_dogs/images.tar')\n",
    "            print(\"\\nDescargando anotaciones...\")\n",
    "            wget.download(annotations_url, 'stanford_dogs/annotation.tar')\n",
    "            print(\"\\nDescargando listas...\")\n",
    "            wget.download(lists_url, 'stanford_dogs/lists.tar')\n",
    "            \n",
    "            # Extraer archivos\n",
    "            for tar_file in ['images.tar', 'annotation.tar', 'lists.tar']:\n",
    "                print(f\"\\nExtrayendo {tar_file}...\")\n",
    "                with tarfile.open(f'stanford_dogs/{tar_file}', 'r') as tar:\n",
    "                    tar.extractall('stanford_dogs/')\n",
    "                os.remove(f'stanford_dogs/{tar_file}')\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error descargando dataset: {e}\")\n",
    "            print(\"Usando dataset alternativo...\")\n",
    "            # Usar torchvision como alternativa\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "download_stanford_dogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d543a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cristhian Ismael\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "C:\\Users\\Cristhian Ismael\\AppData\\Local\\Temp\\ipykernel_30608\\2063229364.py:64: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño dataset entrenamiento: 16464\n",
      "Tamaño dataset validación: 20580\n",
      "Número de clases: 120\n"
     ]
    }
   ],
   "source": [
    "# Preparar dataset con augmentación avanzada\n",
    "class StanfordDogsDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, is_train=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.class_to_idx = {}\n",
    "        \n",
    "        self._load_dataset()\n",
    "    \n",
    "    def _load_dataset(self):\n",
    "        images_dir = os.path.join(self.root_dir, 'Images')\n",
    "        if os.path.exists(images_dir):\n",
    "            classes = sorted(os.listdir(images_dir))\n",
    "            self.class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "            \n",
    "            for class_name in classes:\n",
    "                class_dir = os.path.join(images_dir, class_name)\n",
    "                if os.path.isdir(class_dir):\n",
    "                    for img_name in os.listdir(class_dir):\n",
    "                        if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                            self.images.append(os.path.join(class_dir, img_name))\n",
    "                            self.labels.append(self.class_to_idx[class_name])\n",
    "        else:\n",
    "            # Usar datos sintéticos para demostración\n",
    "            print(\"Generando datos sintéticos para demostración...\")\n",
    "            self.class_to_idx = {f'breed_{i:03d}': i for i in range(120)}\n",
    "            for i in range(12000):  # 100 imágenes por clase\n",
    "                self.images.append(f'synthetic_image_{i}.jpg')\n",
    "                self.labels.append(i % 120)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Cargar imagen o crear sintética\n",
    "        if os.path.exists(img_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            # Imagen sintética para demostración\n",
    "            image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        return image.float(), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Transformaciones con albumentations para mejor rendimiento\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.RandomCrop(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=30, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "    A.Blur(blur_limit=3, p=0.3),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Crear datasets\n",
    "train_dataset = StanfordDogsDataset('stanford_dogs', transform=train_transform, is_train=True)\n",
    "val_dataset = StanfordDogsDataset('stanford_dogs', transform=val_transform, is_train=False)\n",
    "\n",
    "# Split train/val\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, _ = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "print(f'Tamaño dataset entrenamiento: {len(train_dataset)}')\n",
    "print(f'Tamaño dataset validación: {len(val_dataset)}')\n",
    "print(f'Número de clases: {len(train_dataset.dataset.class_to_idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d4005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo creado con 11,548,832 parámetros\n",
      "Parámetros entrenables: 11,548,832\n"
     ]
    }
   ],
   "source": [
    "# Modelo optimizado con EfficientNet y técnicas avanzadas\n",
    "class DogBreedClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=120, model_name='efficientnet_b3'):\n",
    "        super(DogBreedClassifier, self).__init__()\n",
    "        \n",
    "        # Backbone preentrenado\n",
    "        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0)\n",
    "        \n",
    "        # Feature dimension\n",
    "        feature_dim = self.backbone.num_features\n",
    "        \n",
    "        # Clasificador con dropout y batch normalization\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(feature_dim),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(feature_dim, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Inicialización de pesos\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        if len(features.shape) > 2:\n",
    "            features = torch.mean(features, dim=[-2, -1])  # Global average pooling\n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "# Crear modelo optimizado\n",
    "model = DogBreedClassifier(num_classes=120, model_name='efficientnet_b3')\n",
    "model = model.to(device)\n",
    "\n",
    "# Compilar con optimizaciones CUDA\n",
    "if torch.cuda.is_available():\n",
    "    model = torch.jit.script(model)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "\n",
    "print(f'Modelo creado con {sum(p.numel() for p in model.parameters()):,} parámetros')\n",
    "print(f'Parámetros entrenables: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c41c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 32\n",
      "Steps por época: 515\n",
      "Using mixed precision: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristhian Ismael\\AppData\\Local\\Temp\\ipykernel_30608\\3037572908.py:42: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n"
     ]
    }
   ],
   "source": [
    "# Configuración de entrenamiento optimizada\n",
    "batch_size = 32 if torch.cuda.is_available() else 16\n",
    "num_workers = 4\n",
    "\n",
    "# DataLoaders optimizados\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "# Optimizer con weight decay y momentum\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Scheduler con warmup\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-3,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.1,\n",
    "    div_factor=10,\n",
    "    final_div_factor=100\n",
    ")\n",
    "\n",
    "# Loss function con label smoothing\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Métricas\n",
    "scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "\n",
    "print(f'Batch size: {batch_size}')\n",
    "print(f'Steps por época: {len(train_loader)}')\n",
    "print(f'Using mixed precision: {scaler is not None}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eeee3c",
   "metadata": {},
   "source": [
    "# 🏗️ ETAPA 3: ARQUITECTURA DEL MODELO\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1dc255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento...\n",
      "\n",
      "Época 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/515 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Función de entrenamiento optimizada\n",
    "def train_epoch(model, loader, optimizer, criterion, scheduler, scaler=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        total += target.size(0)\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{100.*correct/total:.2f}%',\n",
    "            'LR': f'{scheduler.get_last_lr()[0]:.6f}'\n",
    "        })\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc='Validation')\n",
    "        for data, target in pbar:\n",
    "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
    "            \n",
    "            if scaler is not None:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, target)\n",
    "            else:\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total += target.size(0)\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "# Entrenamiento\n",
    "epochs = 5\n",
    "best_acc = 0\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "print(\"Iniciando entrenamiento...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\nÉpoca {epoch+1}/{epochs}')\n",
    "    \n",
    "    # Entrenamiento\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, scheduler, scaler)\n",
    "    \n",
    "    # Validación\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "    \n",
    "    # Guardar métricas\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    # Guardar mejor modelo\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_acc': best_acc,\n",
    "        }, 'best_dog_classifier.pth')\n",
    "        print(f'Nuevo mejor modelo guardado! Accuracy: {best_acc:.2f}%')\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f'\\nEntrenamiento completado en {training_time/60:.2f} minutos')\n",
    "print(f'Mejor accuracy: {best_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b652b8a2",
   "metadata": {},
   "source": [
    "# 🚀 ETAPA 4: ENTRENAMIENTO\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6daea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de resultados\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(val_losses, label='Val Loss', color='red')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(train_accs, label='Train Acc', color='blue')\n",
    "plt.plot(val_accs, label='Val Acc', color='red')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Learning rate\n",
    "plt.subplot(1, 3, 3)\n",
    "lrs = [scheduler.get_last_lr()[0] for _ in range(len(train_losses))]\n",
    "plt.plot(lrs, color='green')\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estadísticas finales\n",
    "print(f\"\\n=== RESULTADOS FINALES ===\")\n",
    "print(f\"Mejor accuracy de validación: {best_acc:.2f}%\")\n",
    "print(f\"Tiempo total de entrenamiento: {training_time/60:.2f} minutos\")\n",
    "print(f\"Promedio por época: {training_time/epochs:.2f} segundos\")\n",
    "print(f\"Número de parámetros: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Tamaño del modelo: {os.path.getsize('best_dog_classifier.pth')/1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b1190",
   "metadata": {},
   "source": [
    "# 📈 ETAPA 5: EVALUACIÓN Y RESULTADOS\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21396fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de inferencia optimizada\n",
    "def predict_dog_breed(model, image_path, class_names, top_k=5):\n",
    "    model.eval()\n",
    "    \n",
    "    # Cargar y preprocesar imagen\n",
    "    if os.path.exists(image_path):\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        # Imagen sintética para demostración\n",
    "        image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Aplicar transformaciones\n",
    "    transformed = val_transform(image=image)\n",
    "    input_tensor = transformed['image'].unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                output = model(input_tensor)\n",
    "        else:\n",
    "            output = model(input_tensor)\n",
    "        \n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        top_k_probs, top_k_indices = torch.topk(probabilities, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for i in range(top_k):\n",
    "        breed_idx = top_k_indices[0][i].item()\n",
    "        prob = top_k_probs[0][i].item()\n",
    "        breed_name = list(class_names.keys())[breed_idx] if breed_idx < len(class_names) else f'Breed_{breed_idx}'\n",
    "        results.append((breed_name, prob))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Ejemplo de predicción\n",
    "class_names = train_dataset.dataset.class_to_idx\n",
    "example_predictions = predict_dog_breed(model, 'example_dog.jpg', class_names)\n",
    "\n",
    "print(\"\\n=== PREDICCIÓN DE EJEMPLO ===\")\n",
    "for i, (breed, prob) in enumerate(example_predictions, 1):\n",
    "    print(f\"{i}. {breed}: {prob*100:.2f}%\")\n",
    "\n",
    "print(\"\\n¡Modelo de clasificación de razas de perros completado!\")\n",
    "print(\"Características implementadas:\")\n",
    "print(\"✓ EfficientNet-B3 como backbone\")\n",
    "print(\"✓ Data augmentation avanzado con Albumentations\")\n",
    "print(\"✓ Optimización CUDA con mixed precision\")\n",
    "print(\"✓ Scheduler OneCycleLR con warmup\")\n",
    "print(\"✓ Label smoothing y regularización\")\n",
    "print(\"✓ 120 clases de razas caninas\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
